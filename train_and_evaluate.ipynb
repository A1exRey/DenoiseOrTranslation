{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers SentencePiece\n",
    "!git clone https://github.com/huggingface/transformers\n",
    "!pip install -r /content/transformers/examples/pytorch/summarization/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартная модель rut5 обучается через скрипт суммаризатора бибилиотеки трансформер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /content/transformers/examples/pytorch/summarization/run_summarization.py \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path \"sberbank-ai/ruT5-large\" \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --warmup_ratio 0.1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --train_file /content/train.csv \\\n",
    "    --validation_file /content/valid.csv \\\n",
    "    --source_prefix \"\" \\\n",
    "    --output_dir /content/rut5-large_1/ \\\n",
    "    --overwrite_output_dir \\\n",
    "    --per_device_train_batch_size 4 \\\n",
    "    --per_device_eval_batch_size 4 \\\n",
    "    --text_column 'toxic_comment' \\\n",
    "    --summary_column 'neutral_comment' \\\n",
    "    --save_total_limit 8 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --logging_strategy \"epoch\" \\\n",
    "    --evaluation_strategy \"epoch\" \\\n",
    "    --save_strategy \"epoch\" \\\n",
    "    --predict_with_generate \\\n",
    "    --max_source_length 128 \\\n",
    "    --max_target_length 128 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели DisCO И LevT Обучаются через измененную бибилотеку fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile setup.sh\n",
    "\n",
    "export CUDA_HOME=/usr/local/cuda-11.1\n",
    "git clone https://github.com/jungokasai/deep-shallow.git\n",
    "cd deep-shallow\n",
    "python setup.py build_ext --inplace\n",
    "sudo -E pip install --editable ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЕСЛИ ЧТО-ТО СЛОМАЛОСЬ\n",
    "! echo $PYTHONPATH\n",
    "import os \n",
    "os.environ['PYTHONPATH'] += \":/content/deep-shallow/\"\n",
    "! echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дистилляция датасета используется русский корпус Лейпцига"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ЭТО ДИСКО\n",
    "fairseq-train \\\n",
    "    /paraphrase_ru_big_bin/ \\\n",
    "    --save-dir /checkpoints \\\n",
    "    --ddp-backend=no_c10d \\\n",
    "    --task translation_lev \\\n",
    "    --criterion nat_loss \\\n",
    "    --arch disco_transformer \\\n",
    "    --noise no_noise  --fp16 \\\n",
    "    --share-all-embeddings \\\n",
    "    --optimizer adam --adam-betas '(0.9,0.98)' \\\n",
    "    --lr 0.0005 --lr-scheduler inverse_sqrt \\\n",
    "    --min-lr '1e-09' --warmup-updates 10000 \\\n",
    "    --warmup-init-lr '1e-07' --label-smoothing 0.1 \\\n",
    "    --dropout 0.2 --weight-decay 0.01 \\\n",
    "    --decoder-learned-pos \\\n",
    "    --encoder-learned-pos \\\n",
    "    --apply-bert-init \\\n",
    "    --log-format 'simple' --log-interval 1000 \\\n",
    "    --fixed-validation-seed 7 \\\n",
    "    --max-tokens 16000 \\\n",
    "    --save-interval-updates 10000 \\\n",
    "    --max-update 300000 --skip-invalid-size-inputs-valid-test\n",
    "\n",
    "# ЭТО ЛЕВЕНШТЕЙН\n",
    "fairseq-train \\\n",
    "    /paraphrase_ru_big_bin/ \\\n",
    "    --save-dir /checkpoints \\\n",
    "    --ddp-backend=no_c10d \\\n",
    "    --task translation_lev \\\n",
    "    --criterion nat_loss \\\n",
    "    --arch levenshtein_transformer \\\n",
    "    --noise random_delete \\\n",
    "    --share-all-embeddings \\\n",
    "    --optimizer adam --adam-betas '(0.9,0.98)' \\\n",
    "    --lr 0.0005 --lr-scheduler inverse_sqrt \\\n",
    "    --min-lr '1e-09' --warmup-updates 10000 \\\n",
    "    --warmup-init-lr '1e-07' --label-smoothing 0.1 \\\n",
    "    --dropout 0.3 --weight-decay 0.01 \\\n",
    "    --decoder-learned-pos \\\n",
    "    --encoder-learned-pos \\\n",
    "    --apply-bert-init \\\n",
    "    --log-format 'simple' --log-interval 1000 \\\n",
    "    --fixed-validation-seed 7 \\\n",
    "    --max-tokens 16000 \\\n",
    "    --save-interval-updates 10000 \\\n",
    "    --max-update 300000 --skip-invalid-size-inputs-valid-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ГЕНЕРАЦИЯ ДИСКО\n",
    "#                        [--iter-decode-eos-penalty N]\n",
    "#                        [--iter-decode-max-iter N]\n",
    "#                        [--iter-decode-force-max-iter]\n",
    "#                        [--iter-decode-with-beam N]\n",
    "#                        [--iter-decode-with-external-reranker]\n",
    "!fairseq-generate \\\n",
    "    /detox_ru_bin \\\n",
    "    --gen-subset predictnew10 --dataset-impl raw \\\n",
    "    --task translation_lev \\\n",
    "    --path /content/russe_detox_2022-main/checkpoint_last.pt \\\n",
    "    --iter-decode-max-iter 12 \\\n",
    "    --iter-decode-eos-penalty 0 \\\n",
    "    --beam 8 --remove-bpe \\\n",
    "    --print-step \\\n",
    "    --batch-size 220 \\\n",
    "    --decoding-format easy-first --skip-invalid-size-inputs-valid-test  > /content/tmp/data_text40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ГЕНЕРАЦИЯ ЛЕВЕНШТЕЙН\n",
    "#    --path /new_models_disco_and_lev/checkpoint_best_lev.pt \\\n",
    "!fairseq-generate \\\n",
    "    /detox_ru_bin \\\n",
    "    --gen-subset test_small --dataset-impl raw \\\n",
    "    --task translation_lev \\\n",
    "    --path /new_models_for_detox/checkpoint_best2_lev.pt \\\n",
    "    --iter-decode-max-iter 16 \\\n",
    "    --iter-decode-eos-penalty 0 \\\n",
    "    --beam 6 --remove-bpe \\\n",
    "    --print-step \\\n",
    "    --batch-size 100 \\\n",
    "    > /content/tmp/data_text10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /content/natural_order\n",
    "\n",
    "!grep ^S /content/tmp/data_text10 | LC_ALL=C sort -V | cut -f2- > /content/natural_order/src.txt\n",
    "!grep ^T /content/tmp/data_text10 | LC_ALL=C sort -V | cut -f2- > /content/natural_order/ref.txt\n",
    "!grep ^H /content/tmp/data_text10 | LC_ALL=C sort -V | cut -f3- > /content/natural_order/hyp.txt"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
